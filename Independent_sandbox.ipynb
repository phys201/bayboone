{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "handy-gospel",
   "metadata": {},
   "source": [
    "# Sandbox notebook: \n",
    "    \n",
    "This notebook is for testing functions in peices while also viewing their output, plotting etc., (the things you're not really supposed to have in tests)\n",
    "It's designed to run independent of any other parts of the package, just in case.\n",
    "\n",
    "First order of business: Try to get the model creation function to accept multiple inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies and data visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-reserve",
   "metadata": {},
   "source": [
    "The inputs for our new function are:\n",
    "   - num_neutrinos: array of floats\n",
    "        - The number of muon neutrinos shot at the detector in each energy bin\n",
    "   - num_nue: array of floats\n",
    "        - The number of electron neutrinos detected in each energy bin\n",
    "   - energy_bins: array of floats\n",
    "       - bins edges for the energies we've biined data into\n",
    "   - est_ss2t: float between 0 and 1\n",
    "       - estimated ss2t from previous experiments, for use in the prior\n",
    "   - est_dms: float above 0\n",
    "       - estimated dms from previous experiments, also for use in prior\n",
    "       \n",
    "       \n",
    "We'll use \n",
    "   - num_neutrinos: 600000\n",
    "   - num_nue: array of floats, calulated below\n",
    "   - energy_bins: \\[0.01, 0.3, 0.7, 1.5, 2\\]\n",
    "   - est_ss2t: 0.5\n",
    "   - est_dms: 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all out inputs\n",
    "\n",
    "UC = 1.27 #Unit conversion factor for the coefficient on dms in the oscillation probability\n",
    "\n",
    "energy_bins = np.array([0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,1.0,1.2, 1.5, 2]) #(To be used once everything is working properly.)\n",
    "num_neutrinos = np.full(energy_bins.size-1, 600000) #to fit one rate only, use an int for num_neutrinos\n",
    "\n",
    "est_ss2t = 0.2\n",
    "est_dms = 0.8\n",
    "\n",
    "# Define L and E\n",
    "# These shouldn't be exact, but for testing, we'll be lazy\n",
    "E = np.zeros(energy_bins.size-1)\n",
    "for i in range(E.size):\n",
    "    E[i] = energy_bins[i]+(energy_bins[i+1]-energy_bins[i])/2\n",
    "L = 0.5 \n",
    "\n",
    "num_nue = num_neutrinos*est_ss2t*(np.sin(est_dms*UC*L/E))**2\n",
    "true_rates =est_ss2t*(np.sin(est_dms*UC*L/E))**2\n",
    "print(true_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-evaluation",
   "metadata": {},
   "source": [
    "# Begin to define what will eventually be the function that sets up our model\n",
    "\n",
    "First, we look at taking the things we want to be inputs to the function, and making sure they are in the correct useable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we can get values to use as mean energy from our bin edges when we use a truncated normal\n",
    "energies = np.zeros(energy_bins.size-1)\n",
    "sigmas = np.zeros(energy_bins.size-1)\n",
    "for i in range(energies.size):\n",
    "    energies[i] = energy_bins[i] + (energy_bins[i+1]-energy_bins[i])/2\n",
    "    sigmas[i] = (energy_bins[i+1]-energy_bins[i]) # Most energy reconstructions aim for the standard deviation to be about the bin width. Later, we can upadate to make this a keyword argument\n",
    "    \n",
    "# When we attempt to use a uniform distribution for energy, these should be the edges      \n",
    "energies_high = np.array(energy_bins[1:])\n",
    "energies_low = np.array(energy_bins[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-draft",
   "metadata": {},
   "source": [
    "Now we set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "osc_model = pm.Model()\n",
    "with osc_model:\n",
    "        \n",
    "    # We don't know the exact production point of each neutrino, so we draw from a truncated gaussian (enforcing positive distance travelled)   \n",
    "    L = pm.TruncatedNormal('L', mu = 0.500, sigma = 0.01, lower = 0.02, upper = 0.6) #units of km\n",
    "    \n",
    "    #If this works, we'll have one E distribution for each energy bin\n",
    "    #E = energies #\n",
    "    pm.TruncatedNormal('E', mu = energies, sigma = sigmas, lower = energies_low, shape=energies.shape[0]) #units of GeV\n",
    "        \n",
    "    # Priors for unknown model parameters, centered on a prior estimate of ss2t, dms\n",
    "    # Est_ss2t, est_dms defined in previous cell, will be input parameters in our function\n",
    "    ss2t = pm.TruncatedNormal('sin^2_2theta', mu = est_ss2t, sigma = 0.1, lower = 0, upper = 1 ) #pm.Uniform('sin^2_2theta', 0.0001, 1)\n",
    "    dms = pm.TruncatedNormal('delta_m^2', mu = est_dms, sigma = 0.1, lower = 0, shape = (1))\n",
    "        \n",
    "    # In the large n limit, because the number of oscillations is low, we use a Poisson approximation\n",
    "    rate = pm.Deterministic('rate', ss2t*(np.sin(dms*(UC*L)/E))**2)\n",
    "        \n",
    "    #Likelihood of observations\n",
    "    measurements = pm.Poisson('nue_flux', mu = rate*num_neutrinos, observed = num_nue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "osc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-situation",
   "metadata": {},
   "source": [
    "\n",
    "Okay, this looks good! Next order of business:\n",
    "    \n",
    "## Get model comparison to work with the multiple-input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-heritage",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_draws = 1000\n",
    "tuning_steps = 1000\n",
    "with osc_model:\n",
    "    trace = pm.sample(num_draws, tune= tuning_steps)\n",
    "    az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-caution",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "We see that we're not properly telling the sampler that there should be multiple values for E, and conseqently, the rate. What we'd like to do is have a value of E and rate for each bin, and the same value across all bins for $sin^2(2\\theta)$, $\\Delta m^2$, and L. \n",
    "\n",
    "Just in case, we wan to still check the marginal distributions of $sin^2(2\\theta)$, $\\Delta m^2$. However, we've defined some of these quantities incorrectly, so it's not workgin (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pm.trace_to_dataframe(trace)\n",
    "params_0 = pm.trace_to_dataframe(trace, chains =  0)\n",
    "params_1 = pm.trace_to_dataframe(trace, chains =  1)\n",
    "params_2 = pm.trace_to_dataframe(trace, chains =  2)\n",
    "params_3 = pm.trace_to_dataframe(trace, chains =  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [params_0.mean(), params_1.mean(), params_2.mean(), params_3.mean()]\n",
    "headers = ['params_0', 'params_1', 'params_2', 'params_3']\n",
    "means_df = pd.concat(means, axis=1, keys=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df.loc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-spokesman",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joint_kde = sns.jointplot(x='delta_m^2__0', y='sin^2_2theta', data=params, kind='scatter', s=0.2)\n",
    "\n",
    "#joint_kde.ax_marg_x.set_xlim(0, 10)\n",
    "#joint_kde.ax_marg_y.set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-potato",
   "metadata": {},
   "source": [
    "Now we want to confirm that for a given energy bin, each chain is finding $\\Delta m^2$, $sin^2(2\\theta)$ values that give rates consistent with those in the other chains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-corporation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy_0 = np.full(4, energies[0])\n",
    "energy_2 = np.full(4, energies[2])\n",
    "energy_3 = np.full(4, energies[3])\n",
    "energy_5 = np.full(4, energies[5])\n",
    "energy_7 = np.full(4, energies[7])\n",
    "energy_9 = np.full(4, energies[9])\n",
    "\n",
    "plt.scatter(energy_0, means_df.loc['rate__0'])\n",
    "plt.scatter(energy_2, means_df.loc['rate__2'])\n",
    "plt.scatter(energy_3, means_df.loc['rate__3'])\n",
    "plt.scatter(energy_5, means_df.loc['rate__5'])\n",
    "plt.scatter(energy_7, means_df.loc['rate__7'])\n",
    "plt.scatter(energy_9, means_df.loc['rate__9'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-designation",
   "metadata": {},
   "source": [
    "We note that the when the chains have lengths which agree exactly, the rates which come out of the fit agree as well. When there are slight differences in length between the chains, the largest differences between estimated rates appear in the 0.2 to 0.8 GeV region, exactly where we expect to be most sensitive to the low-energy excess.This is to be expected given the L dependence in the $sin^2(1.27\\Delta m^2 L/E)$ of the oscillation formula, and illustrates one of the difficulties inherent in short-baseline experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-jenny",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trace = pm.trace_to_dataframe(trace)\n",
    "q = df_trace.quantile([0.16,0.50,0.84], axis=0)\n",
    "print(\"delta_m^2 = {:.2f} + {:.2f} - {:.2f}\".format(q['delta_m^2__0'][0.50], \n",
    "                                            q['delta_m^2__0'][0.84]-q['delta_m^2__0'][0.50],\n",
    "                                            q['delta_m^2__0'][0.50]-q['delta_m^2__0'][0.16]))\n",
    "print(\"sin^2_2theta = {:.1f} + {:.1f} - {:.1f}\".format(q['sin^2_2theta'][0.50], \n",
    "                                            q['sin^2_2theta'][0.84]-q['sin^2_2theta'][0.50],\n",
    "                                            q['sin^2_2theta'][0.50]-q['sin^2_2theta'][0.16]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 1.0\n",
    "L = 0.54\n",
    "ss2t = np.linspace(0, 1, 1000)\n",
    "rate = [0.1, 0.2, 0.5, 0.7]\n",
    "dms_0 = E/(UC*L) * np.arcsin(np.sqrt(rate[0]/ss2t))\n",
    "dms_3 = E/(UC*L) * np.arcsin(np.sqrt(rate[3]/ss2t))\n",
    "\n",
    "\n",
    "plt.plot(ss2t, dms_0, color='red')\n",
    "plt.plot(ss2t, dms_3, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = means_df.loc['L']\n",
    "ss2t = np.linspace(0.0, 1, 1000)\n",
    "\n",
    "def give_dms(energy, L, rate, ss2t):\n",
    "    dms = energy/(UC*L) * np.arcsin(np.sqrt(rate/ss2t))\n",
    "    return dms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "ax1.set_ylabel('delta_m^2')\n",
    "ax1.set_xlabel('sin^2_2theta')\n",
    "\n",
    "for i in [0]:#play around with this! Choose any energy bin to investigate (I recommend only one or two at a time, otherwise the legend takes over.)\n",
    "    E_str = \"{:.2f}\".format(energies[i])\n",
    "    labe = 'mean at E = ' + E_str\n",
    "    ax1.plot(ss2t, give_dms(energies[i], params.mean().loc['L'], params.mean().loc[rate_str], ss2t), label = labe)\n",
    "    ax1.scatter(params.mean().loc['sin^2_2theta'], params.mean().loc['delta_m^2__0'])      \n",
    "    for chain in range(0, 4):\n",
    "        rate_str = 'rate__' + str(i)\n",
    "        rate = means_df.loc[rate_str]\n",
    "        L_str = \"{:.3f}\".format(L[chain])\n",
    "        label_str = 'L = ' + L_str +', E = '+ E_str + ', chain ' + str(chain)\n",
    "        ax1.plot(ss2t, give_dms(energies[i], L[chain], rate[chain], ss2t), label = label_str)\n",
    "        ax1.scatter(means_df.loc['sin^2_2theta'][chain], means_df.loc['delta_m^2__0'][chain])\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-savannah",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-constant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-signature",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
